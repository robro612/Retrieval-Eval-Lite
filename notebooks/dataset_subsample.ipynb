{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# do this to prevent JAX from planting itself on every GPU and pre-allocating 75% of memory on GPU:0\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rjha/miniforge3/envs/dataset_subsample/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-07-09 13:20:07.729558: W external/xla/xla/service/gpu/nvptx_compiler.cc:765] The NVIDIA driver's CUDA version is 12.3 which is older than the ptxas CUDA version (12.5.82). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "import bm25s\n",
    "import Stemmer\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import pyterrier as pt\n",
    "import ir_datasets\n",
    "from typing import Optional, List, Dict, Any, Tuple\n",
    "from pyterrier.measures import nDCG, R, AP\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.1 has loaded Terrier 5.9 (built by craigm on 2024-05-02 17:40) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_name: str) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    dataset = ir_datasets.load(dataset_name)\n",
    "\n",
    "    queries = pd.DataFrame(dataset.queries_iter())[[\"query_id\", \"text\"]].rename(columns={\"query_id\": \"qid\", \"text\" : \"query\"})\n",
    "\n",
    "    qrels = pd.DataFrame(dataset.qrels_iter()).iloc[:, :3].rename(columns={\"query_id\" : \"qid\", \"doc_id\" : \"docno\", \"relevance\" : \"label\"})\n",
    "\n",
    "    corpus = pd.DataFrame(dataset.docs_iter())\n",
    "    \n",
    "    if \"title\" in corpus.columns:\n",
    "        corpus['text'] = corpus['title'] + ' | ' + corpus['text']\n",
    "\n",
    "    corpus = corpus[[\"doc_id\", \"text\"]].rename(columns={\"doc_id\" : \"docno\"})\n",
    "\n",
    "    return corpus, queries, qrels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [starting] opening zip file\n",
      "[INFO] If you have a local copy of https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/msmarco.zip, you can symlink it here to avoid downloading it again: /home/rjha/.ir_datasets/downloads/444067daf65d982533ea17ebd59501e4\n",
      "[INFO] [starting] https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/msmarco.zip\n",
      "[INFO] [finished] https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/msmarco.zip: [00:27] [1.08GB] [39.6MB/s]\n",
      "[INFO] [finished] opening zip file [27.57s]                                                                \n",
      "[INFO] [starting] opening zip file\n",
      "[INFO] [finished] opening zip file [0ms]\n",
      "[INFO] [starting] building docstore\n",
      "[INFO] [starting] opening zip file                                              \n",
      "[INFO] [finished] opening zip file [2ms]                                        \n",
      "docs_iter: 100%|██████████████████| 8841823/8841823 [01:36<00:00, 91629.34doc/s]\n",
      "[INFO] [finished] docs_iter: [01:36] [8841823doc] [91628.69doc/s]\n",
      "[INFO] [finished] building docstore [01:37]\n"
     ]
    }
   ],
   "source": [
    "corpus, queries, qrels = load_dataset(\"beir/msmarco/dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents are [docno, text]\n",
    "Document = namedtuple(\"Document\", [\"docno\", \"text\"])\n",
    "# queries are [qid, query]\n",
    "Query = namedtuple(\"Query\", [\"qid\", \"query\"])\n",
    "# qrels are [qid, docno, label]\n",
    "Qrel = namedtuple(\"Qrel\", [\"qid\", \"docno\", \"label\"])\n",
    "# retrieval results are a pd.DataFrame with [qid, docno, score, rank]\n",
    "Result = namedtuple(\"Result\", [\"qid\", \"docno\", \"score\", \"rank\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25s(pt.Transformer):\n",
    "    def __init__(self, corpus: pd.DataFrame, lang=\"en\", stemmer: Optional[Stemmer.Stemmer] = None, index_path: Optional[str] = None, load_index: bool = False):\n",
    "        self.corpus = corpus\n",
    "        self.lang = lang\n",
    "        self.stemmer = stemmer\n",
    "        self.index_path = index_path\n",
    "\n",
    "        if load_index:\n",
    "            print(f\"Loading index from {self.index_path}\")\n",
    "            self.retriever = bm25s.BM25.load(self.index_path)\n",
    "        else:\n",
    "            self.retriever = bm25s.BM25()\n",
    "            corpus_tokens = bm25s.tokenize(corpus[\"text\"].to_list(), stopwords=lang, stemmer=self.stemmer)\n",
    "            self.retriever.index(corpus_tokens)\n",
    "\n",
    "            if self.index_path is not None:\n",
    "                print(f\"Saving index to {self.index_path}\")\n",
    "                self.retriever.save(self.index_path)\n",
    "\n",
    "    def transform(self, queries: pd.DataFrame) -> pd.DataFrame:\n",
    "        query_token_ids = bm25s.tokenize(queries[\"query\"].to_list(), stopwords=self.lang, stemmer=self.stemmer)\n",
    "        docnos, scores = self.retriever.retrieve(query_token_ids, corpus=self.corpus[\"docno\"].to_list(), k=1000)\n",
    "        results = pd.DataFrame(\n",
    "            [\n",
    "                Result(qid=qid, docno=docno, score=score, rank=rank)\n",
    "                for qid, docnos_i, scores_i in zip(queries[\"qid\"], docnos, scores)\n",
    "                for rank, (docno, score) in enumerate(zip(docnos_i, scores_i), start=1)\n",
    "            ]\n",
    "        )\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample_corpus(corpus, qrels, results, top_k=50):\n",
    "    if top_k < 0: return corpus\n",
    "    judged = set(qrels.docno)\n",
    "    top_k_docnos = set(results.groupby(by=\"qid\").apply(lambda x: x.nlargest(top_k, 'score'), include_groups=False).reset_index(drop=True).docno)\n",
    "    keep_docnos = judged.union(top_k_docnos)\n",
    "    print(top_k, len(keep_docnos))\n",
    "    return corpus[corpus['docno'].isin(keep_docnos)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_experiment(dataset: str, corpus: pd.DataFrame, queries: pd.DataFrame, qrels: pd.DataFrame, top_ks: List[int] = [1,10,50,100,250,500], load_index: bool = False, load_sub_indices: bool = False) -> pd.DataFrame:\n",
    "    \n",
    "    index_prefix = os.path.join(\"indexes\", dataset)\n",
    "    # make full-fidelity retriever\n",
    "    print(\"Indexing and retrieving from full corpus\")\n",
    "    bm25_full_corpus = BM25s(corpus, lang=\"en\", stemmer=Stemmer.Stemmer(\"english\"), index_path=os.path.join(index_prefix, \"full_corpus\"), load_index=load_index)\n",
    "    results_full_corpus = bm25_full_corpus.transform(queries)\n",
    "\n",
    "    subsampled_corpora = {\n",
    "        top_k : subsample_corpus(corpus, qrels, results_full_corpus, top_k=top_k)\n",
    "        for top_k in top_ks\n",
    "    }\n",
    "    \n",
    "    subsampled_corpus_size = {\n",
    "        top_k : len(ss_corpus) for top_k, ss_corpus in subsampled_corpora.items()\n",
    "    }\n",
    "    print(subsampled_corpus_size)\n",
    "\n",
    "    print(\"Generating and indexing corpus subsets\")\n",
    "    retrievers = {\n",
    "        \"bm25_full_corpus\" : bm25_full_corpus,\n",
    "        ** {\n",
    "            f\"bm25_top_{top_k}_corpus\" : BM25s(ss_corpus, lang=\"en\", stemmer=Stemmer.Stemmer(\"english\"), index_path=os.path.join(index_prefix, f\"top_{top_k}_corpus\"), load_index=load_sub_indices)\n",
    "            for top_k, ss_corpus in subsampled_corpora.items()\n",
    "        }\n",
    "    }\n",
    "\n",
    "    metrics = [metric@k for k in (1, 10 ,100, 1000) for metric in [nDCG, R, AP]]\n",
    "\n",
    "    print(\"Executing retrieval\")\n",
    "    results = pt.Experiment(\n",
    "        list(retrievers.values()),\n",
    "        queries,\n",
    "        qrels,\n",
    "        eval_metrics=metrics,\n",
    "        names=list(retrievers.keys()),\n",
    "    )\n",
    "\n",
    "    return results, subsampled_corpus_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Don't run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_s = BM25s(corpus, lang=\"en\", stemmer=Stemmer.Stemmer(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_fidelity_results = bm25_s.transform(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier.measures import nDCG, R\n",
    "\n",
    "pt.Experiment(\n",
    "    [full_fidelity_results],\n",
    "    queries,\n",
    "    qrels,\n",
    "    eval_metrics=[nDCG@10, R@1000],\n",
    "    names=[\"bm25_full\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsampled_corpora = {\n",
    "    top_k : subsample_corpus(corpus, qrels, full_fidelity_results, top_k=top_k)\n",
    "    for top_k in [1, 10, 50, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ks = [1, 10, 50, 100]\n",
    "\n",
    "results = pt.Experiment(\n",
    "    [full_fidelity_results, *[BM25s(ss_corpus, lang=\"en\", stemmer=Stemmer.Stemmer(\"english\")) for ss_corpus in subsampled_corpora.values()]],\n",
    "    queries,\n",
    "    qrels,\n",
    "    eval_metrics=[metric@k for k in (1, 10 ,100, 1000) for metric in [nDCG, R, AP]],\n",
    "    names=[\"bm25_full_fidelity\", *[f\"bm25_subsample_topk={top_k}\" for top_k in subsampled_corpora.keys()]],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing and retrieving from full corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving index to indexes/msmarco/full_corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 13676\n",
      "10 72067\n",
      "50 316541\n",
      "100 595331\n",
      "250 1320888\n",
      "500 2293128\n",
      "{1: 13676, 10: 72067, 50: 316541, 100: 595331, 250: 1320888, 500: 2293128}\n",
      "Generating and indexing corpus subsets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving index to indexes/msmarco/top_1_corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving index to indexes/msmarco/top_10_corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving index to indexes/msmarco/top_50_corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving index to indexes/msmarco/top_100_corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving index to indexes/msmarco/top_250_corpus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving index to indexes/msmarco/top_500_corpus\n",
      "Executing retrieval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    }
   ],
   "source": [
    "results = dataset_experiment(\"msmarco\", corpus, queries, qrels, load_index=False, load_sub_indices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tuple = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, corpus_sizes = results_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nDCG@1</th>\n",
       "      <th>R@1</th>\n",
       "      <th>AP@1</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>R@10</th>\n",
       "      <th>AP@10</th>\n",
       "      <th>nDCG@100</th>\n",
       "      <th>R@100</th>\n",
       "      <th>AP@100</th>\n",
       "      <th>nDCG@1000</th>\n",
       "      <th>R@1000</th>\n",
       "      <th>AP@1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bm25_full_corpus</td>\n",
       "      <td>0.095415</td>\n",
       "      <td>0.092646</td>\n",
       "      <td>0.092646</td>\n",
       "      <td>0.218882</td>\n",
       "      <td>0.369269</td>\n",
       "      <td>0.170875</td>\n",
       "      <td>0.279009</td>\n",
       "      <td>0.656996</td>\n",
       "      <td>0.182402</td>\n",
       "      <td>0.303712</td>\n",
       "      <td>0.852089</td>\n",
       "      <td>0.183275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bm25_top_1_corpus</td>\n",
       "      <td>0.105014</td>\n",
       "      <td>0.101552</td>\n",
       "      <td>0.101552</td>\n",
       "      <td>0.573097</td>\n",
       "      <td>0.908656</td>\n",
       "      <td>0.457534</td>\n",
       "      <td>0.587220</td>\n",
       "      <td>0.972254</td>\n",
       "      <td>0.460695</td>\n",
       "      <td>0.589587</td>\n",
       "      <td>0.990831</td>\n",
       "      <td>0.460784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bm25_top_10_corpus</td>\n",
       "      <td>0.097135</td>\n",
       "      <td>0.093911</td>\n",
       "      <td>0.093911</td>\n",
       "      <td>0.230125</td>\n",
       "      <td>0.398436</td>\n",
       "      <td>0.176935</td>\n",
       "      <td>0.366475</td>\n",
       "      <td>0.934945</td>\n",
       "      <td>0.215404</td>\n",
       "      <td>0.372271</td>\n",
       "      <td>0.979585</td>\n",
       "      <td>0.215635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bm25_top_50_corpus</td>\n",
       "      <td>0.097708</td>\n",
       "      <td>0.094413</td>\n",
       "      <td>0.094413</td>\n",
       "      <td>0.223571</td>\n",
       "      <td>0.376409</td>\n",
       "      <td>0.174704</td>\n",
       "      <td>0.313700</td>\n",
       "      <td>0.835840</td>\n",
       "      <td>0.189470</td>\n",
       "      <td>0.330067</td>\n",
       "      <td>0.959241</td>\n",
       "      <td>0.190170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bm25_top_100_corpus</td>\n",
       "      <td>0.097278</td>\n",
       "      <td>0.094222</td>\n",
       "      <td>0.094222</td>\n",
       "      <td>0.223829</td>\n",
       "      <td>0.377483</td>\n",
       "      <td>0.174739</td>\n",
       "      <td>0.286159</td>\n",
       "      <td>0.680110</td>\n",
       "      <td>0.186374</td>\n",
       "      <td>0.322265</td>\n",
       "      <td>0.944257</td>\n",
       "      <td>0.188099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bm25_top_250_corpus</td>\n",
       "      <td>0.096991</td>\n",
       "      <td>0.093935</td>\n",
       "      <td>0.093935</td>\n",
       "      <td>0.223429</td>\n",
       "      <td>0.377412</td>\n",
       "      <td>0.174280</td>\n",
       "      <td>0.282986</td>\n",
       "      <td>0.662011</td>\n",
       "      <td>0.185726</td>\n",
       "      <td>0.315219</td>\n",
       "      <td>0.916846</td>\n",
       "      <td>0.186834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bm25_top_500_corpus</td>\n",
       "      <td>0.096275</td>\n",
       "      <td>0.093290</td>\n",
       "      <td>0.093290</td>\n",
       "      <td>0.222611</td>\n",
       "      <td>0.375621</td>\n",
       "      <td>0.173737</td>\n",
       "      <td>0.282635</td>\n",
       "      <td>0.662297</td>\n",
       "      <td>0.185293</td>\n",
       "      <td>0.310934</td>\n",
       "      <td>0.889625</td>\n",
       "      <td>0.186229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name    nDCG@1       R@1      AP@1   nDCG@10      R@10  \\\n",
       "0     bm25_full_corpus  0.095415  0.092646  0.092646  0.218882  0.369269   \n",
       "1    bm25_top_1_corpus  0.105014  0.101552  0.101552  0.573097  0.908656   \n",
       "2   bm25_top_10_corpus  0.097135  0.093911  0.093911  0.230125  0.398436   \n",
       "3   bm25_top_50_corpus  0.097708  0.094413  0.094413  0.223571  0.376409   \n",
       "4  bm25_top_100_corpus  0.097278  0.094222  0.094222  0.223829  0.377483   \n",
       "5  bm25_top_250_corpus  0.096991  0.093935  0.093935  0.223429  0.377412   \n",
       "6  bm25_top_500_corpus  0.096275  0.093290  0.093290  0.222611  0.375621   \n",
       "\n",
       "      AP@10  nDCG@100     R@100    AP@100  nDCG@1000    R@1000   AP@1000  \n",
       "0  0.170875  0.279009  0.656996  0.182402   0.303712  0.852089  0.183275  \n",
       "1  0.457534  0.587220  0.972254  0.460695   0.589587  0.990831  0.460784  \n",
       "2  0.176935  0.366475  0.934945  0.215404   0.372271  0.979585  0.215635  \n",
       "3  0.174704  0.313700  0.835840  0.189470   0.330067  0.959241  0.190170  \n",
       "4  0.174739  0.286159  0.680110  0.186374   0.322265  0.944257  0.188099  \n",
       "5  0.174280  0.282986  0.662011  0.185726   0.315219  0.916846  0.186834  \n",
       "6  0.173737  0.282635  0.662297  0.185293   0.310934  0.889625  0.186229  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 13676, 10: 72067, 50: 316541, 100: 595331, 250: 1320888, 500: 2293128}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8841823"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your data is already in a DataFrame named results\n",
    "\n",
    "# Metrics to consider\n",
    "metrics = ['nDCG', 'R', 'AP']\n",
    "top_k_values = [1, 10, 100, 1000]\n",
    "\n",
    "# Initialize a figure with subplots\n",
    "fig, axes = plt.subplots(nrows=len(metrics), ncols=1, figsize=(10, 16), sharex=True)\n",
    "\n",
    "# Iterate over each metric\n",
    "for i, metric in enumerate(metrics):\n",
    "    # Initialize a list to store ratios for each top_k value\n",
    "    ratios = []\n",
    "    \n",
    "    # Calculate ratios relative to bm25_full_corpus for each top_k run\n",
    "    for k in top_k_values:\n",
    "        full_corpus_value = results[f'{metric}@{k}'].iloc[0]\n",
    "        top_k_value = results[f'{metric}@{k}'].iloc[1:]\n",
    "        ratio = top_k_value / full_corpus_value\n",
    "        ratios.append(ratio)\n",
    "    \n",
    "    # Plot ratios\n",
    "    for j, k in enumerate(top_k_values[1:]):  # start from index 1 to skip full_corpus_value\n",
    "        ax = axes[i] if len(metrics) > 1 else axes\n",
    "        ax.plot(results['name'].iloc[1:], ratios[j], marker='o', label=f'{metric}@{k}')\n",
    "    \n",
    "\n",
    "    # Set y-axis label for each subplot\n",
    "    axes[i].set_ylabel(f'{metric} Ratio')\n",
    "\n",
    "     # Set y-axis to log scale and range\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(0.99, 1.1)\n",
    "    \n",
    "    # Add a dotted black line at y=1\n",
    "    ax.axhline(y=1.01, color='red', linestyle='--', label=\"Within 1%\")\n",
    "    ax.axhline(y=1, color='black', linestyle='--', label=\"True Score\")\n",
    "    ax.legend()\n",
    "\n",
    "# Set x-axis label and title\n",
    "axes[-1].set_xlabel('Run Name')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Add legend and display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in results.columns:\n",
    "    if column == \"name\" or \"ratio\" in column: continue\n",
    "    results[column + \"_ratio\"] = results[column] / results[column][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.iloc[:, -12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataset_subsample",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
